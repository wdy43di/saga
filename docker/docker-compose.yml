services:
  saga-core:
    build:
      context: ../saga-core
      dockerfile: Dockerfile
    image: docker-saga-core
    container_name: saga-core
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      - OLLAMA_URL=http://saga-ollama:11434
      - SAGA_MODEL=llama3:latest
      - PYTHONUNBUFFERED=1  # Forces logs to show up in real-time
    volumes:
      - ../saga-core/prompts:/saga/prompts                # Persona/System prompts
      - ../saga-core/static:/app/static                   # Web UI (index.html, styles)
      - ../saga-core/saga_server.py:/app/saga_server.py   # The actual Python logic
      - ../saga-core/memory:/saga/memory                  # Memory stones and PDF uploads
    depends_on:
      - saga-ollama

  saga-ollama:
    image: ollama/ollama:latest
    container_name: saga-ollama
    restart: unless-stopped
    volumes:
      - ../ollama/models:/root/.ollama                    # Keeps downloaded AI models safe
